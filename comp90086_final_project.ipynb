{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp90086_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YsP5Tn-T3iFk",
        "WYwujZee3Xjw",
        "EWXrZecJQn9B",
        "QJzsF7xf7nFB",
        "qBVM-NgL7_hF",
        "T3n9WzV3zczx",
        "Z4-5m9b5XdIi",
        "XrxzlRZPwzrj",
        "dbYc9kJlZwWk",
        "5DqzIj7LcR5v"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhmEQYcV60L0",
        "outputId": "796e8580-852c-4c86-880e-e480dc406bf6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HZFLbrnHkEW"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "dir_project = os.path.join(os.getcwd(), 'drive', 'MyDrive', '研二上 Computer Vision (COMP90086_2021_SM2) 研究生第三学期', 'Final Project')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LKoRKPJHuEF",
        "outputId": "a5ed4558-65a1-405f-8641-ae7070f2696f"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print(cv2.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-MU2CB8jGOT"
      },
      "source": [
        "#code from https://blog.csdn.net/xiaobiyin9140/article/details/84638260\n",
        "\n",
        "train_img_dir = os.path.join(dir_project, 'train')\n",
        "# train_img_dir = os.path.join(train_img_dir, 'img')\n",
        "\n",
        "\n",
        "def read_directory(directory_name):\n",
        "  array_of_img=[]  \n",
        "  for filename in os.listdir(r\"/\"+directory_name):\n",
        "    img = cv2.imread(directory_name + \"/\" + filename)\n",
        "    array_of_img.append(img)\n",
        "    #print(array_of_img)\n",
        "  return array_of_img\n",
        "\n",
        "train_data = read_directory(train_img_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyMsDmAjoRf7"
      },
      "source": [
        "#This line might result in web crash\n",
        "# train_data_deepcopy = copy.deepcopy(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DM7ad-3wA3c",
        "outputId": "99c0673b-e986-4dac-9410-6252f782fb8a"
      },
      "source": [
        "print(train_data_deepcopy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[None, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0hFqgYzzIss"
      },
      "source": [
        "#test_data_deepcopy = copy.deepcopy(test_data)\n",
        "\n",
        "print(len(test_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMj9Xve0niwo"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import platform\n",
        "from operator import itemgetter \n",
        "import time\n",
        "import platform\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n6hDP0bnETS",
        "outputId": "f0f4d0ea-c0c5-45c0-c35b-56b3dfa42c14"
      },
      "source": [
        "# be sure to mount the directory, or it will fail.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdAyS-IdeoV7"
      },
      "source": [
        "# to tackle the inconsistency between local and colab\n",
        "prefix = {\n",
        "    'local' : Path(os.getcwd()).parent,\n",
        "    'colab' : Path(os.path.join(os.getcwd(), 'drive', 'MyDrive', 'semester4', 'COMP90086', 'assignment', 'final_project'))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WDV7ky7ctDZ"
      },
      "source": [
        "prepare the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDx6osDJH1AV"
      },
      "source": [
        "dir_project = prefix['local'] if 'Desktop' in platform.node() else prefix['colab']\n",
        "\n",
        "\n",
        "label_img_dir = Path(os.path.join(dir_project, 'train', 'img'))\n",
        "unlabel_img_dir = Path(os.path.join(dir_project, 'test', 'img'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_KwNpj0zj06"
      },
      "source": [
        "## Convert the csv file to data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFb6nnxMb7Up"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "root_path = label_img_dir.parent # the grader can define your own root_path to load 'train.csv'\n",
        "\n",
        "records = pd.read_csv(os.path.join(root_path, 'train.csv')) # load csv file to be a data frame records\n",
        "\n",
        "# extract file names so that we can easily load images based on this list\n",
        "fnames = list(records['id'])\n",
        "\n",
        "# make the goelocation a label. The format is 'x_y'\n",
        "geoloc = [ f'{x}_{y}' for (x,y) in zip(records['x'],records['y'])]\n",
        "\n",
        "# build a new data frame df with columns 'fname', 'geoloc', and 'geoloc-label'\n",
        "df = pd.DataFrame(list(zip(fnames, geoloc)), columns=['fname', 'geoloc']) \n",
        "\n",
        "# we will use this line to build a new dictionary called \"label2geoloc\"\n",
        "labelencoder = LabelEncoder()\n",
        "df['geoloc-label'] = labelencoder.fit_transform(df['geoloc']) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsP5Tn-T3iFk"
      },
      "source": [
        "## some collections that can help us process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo4EsJpO2Vpp"
      },
      "source": [
        "# 1. label2geoloc : this dic can convert label-encoded index to the label\n",
        "label2geoloc = dict( (label,loc) for loc,label in zip(df['geoloc'], df['geoloc-label']))\n",
        "\n",
        "# 2. m : we can this dictionary to get label-encoded index of the label by giving filename\n",
        "m = {}\n",
        "for (fname, geoloc) in zip(df['fname'], df['geoloc-label']):\n",
        "    key = geoloc\n",
        "    if key not in m:\n",
        "        m[key] = [fname]\n",
        "    else:\n",
        "        m[key].append(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYwujZee3Xjw"
      },
      "source": [
        "## Load the labelled images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biJMdTI63O0S"
      },
      "source": [
        "\n",
        "# input will be the img_dir, the established data frame, and optional args\n",
        "# output will be a tuple object containing 2 numpy arrays\n",
        "\n",
        "def gen_img_set(img_dir, df, **kwargs):\n",
        "    imgs = dict()\n",
        "    img_objs = []\n",
        "    img_labels = []\n",
        "    for (fname, geoloc) in zip(df['fname'], df['geoloc-label']):\n",
        "        img = cv2.imread(filename = os.path.join(img_dir, f'{fname}.jpg'))\n",
        "        if len(kwargs) > 0:\n",
        "            h, w = kwargs['new_dim']\n",
        "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_AREA)\n",
        "        \n",
        "        img_objs.append(img)\n",
        "        img_labels.append(geoloc)\n",
        "        return np.array(img_objs), np.array(img_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D6oP1aY39Bo"
      },
      "source": [
        "# a use case for the above function\n",
        "r = 0.3\n",
        "h, w = (490, 680) # the grader can decide by self.\n",
        "h, w = int(r*h), int(r*w)\n",
        "\n",
        "(train_imgs, train_labels) = gen_img_set(label_img_dir, df, new_dim=(h,w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfiiBIk17MLX"
      },
      "source": [
        "## The following will be 4 cases:\n",
        "\n",
        "\n",
        "1.   use CIFAR-10 to train GoogLeNet for initial evaluation\n",
        "2.   train model with Googlenet and images for this project\n",
        "3.   transfer learning with VGG19\n",
        "4.   calculate similarity by VGG19 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWXrZecJQn9B"
      },
      "source": [
        "## 1. use CIFAR-10 to train GoogLeNet for initial evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KoAXIvdQluL"
      },
      "source": [
        "# load all modules\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import time\n",
        "import platform\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "# prepare dimension for image\n",
        "n = 7500\n",
        "ratio = 0.8\n",
        "dim = 224\n",
        "\n",
        "num_model = 5\n",
        "# cross-validation, expected to train 5 models\n",
        "for i in range(num_model):\n",
        "    # prepare data\n",
        "    ## download data from the inter-network\n",
        "    (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()[0:n]\n",
        "\n",
        "    ## prepare training data and label\n",
        "    train_imgs = np.zeros([int(ratio*n),dim,dim,3], dtype='uint8')\n",
        "    train_labels = y_train[0:int(ratio*n)]\n",
        "\n",
        "    ## prepare testing data and label\n",
        "    test_imgs = np.zeros([int(round((1-ratio)*n,0)) ,dim,dim,3], dtype='uint8')\n",
        "    test_labels = y_test[0:int(round((1-ratio)*n,0))]\n",
        "\n",
        "    ## resize input image for training model to 224x224\n",
        "    for i, img in enumerate(X_train[0:int(ratio*n)]): # (224,224,3)-> (3,224,224)\n",
        "        large_img = cv2.resize(img, dsize=(dim, dim), interpolation=cv2.INTER_CUBIC)\n",
        "        train_imgs[i] = large_img\n",
        "\n",
        "    ## resize input image for testing model to 224x224\n",
        "    for i, img in enumerate(X_test[0:int(round((1-ratio)*n,0))]): # (224,224,3)-> (3,224,224)\n",
        "        large_img = cv2.resize(img, dsize=(dim, dim), interpolation=cv2.INTER_CUBIC)\n",
        "        test_imgs[i] = large_img\n",
        "\n",
        "\n",
        "\n",
        "    # prepare model\n",
        "    ## create the base pre-trained model\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "    ## add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    ## let's add a fully-connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "    ## and a logistic layer -- let's say we have 200 classes\n",
        "    predictions = Dense(1499, activation='softmax')(x)\n",
        "    ## this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    ## compile model\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "               metrics=['accuracy'])\n",
        "\n",
        "    ## train the model\n",
        "    # train and verification\n",
        "    model_history = model.fit(train_imgs, train_labels, \n",
        "                          epochs=10, batch_size=32, \n",
        "                          validation_data=(test_imgs, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJzsF7xf7nFB"
      },
      "source": [
        "## 2. Train model with GoogLeNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIGHURhr7ygZ"
      },
      "source": [
        "# with cross-validation\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# 1.prepare data first\n",
        "h, w = (224,224)\n",
        "(train_imgs, train_labels) = gen_img_set(train_img_dir, df, new_dim=(h,w))\n",
        "\n",
        "\n",
        "\n",
        "# 2. prepare data, sampling from the original to create 3 different sets\n",
        "from sklearn.model_selection import KFold\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
        "\n",
        "\n",
        "X = model_imgs\n",
        "Y = model_labels\n",
        "\n",
        "# 3. prepare model GoogLeNet\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1499, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "# 4. train model. This will train 3 distinct models\n",
        "googlenet_model_histories = []  # record all trained models\n",
        "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
        "    print(f'i={i}')\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), #because we take a coordinate as an independent label.\n",
        "           metrics=['accuracy'])\n",
        "    model_history = model.fit(X[train], Y[train], epochs=10, batch_size=10, validation_data=(X[test], Y[test]))\n",
        "    \n",
        "    y_true = np.array(Y[test])\n",
        "    y_pred = gen_pred_labels(model.predict(X[test]))\n",
        "    error = compute_err(y_pred, y_true, label2geoloc)\n",
        "    print(error)\n",
        "    \n",
        "    googlenet_model_histories.append(model_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBVM-NgL7_hF"
      },
      "source": [
        "## Transfer learning with VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPbbeqR8Dwd"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "# 1.prepare data first\n",
        "r = 0.3\n",
        "h, w = list(imgs_raw.values())[0].shape[:2]\n",
        "h, w = int(r*h), int(r*w)\n",
        "\n",
        "(train_imgs, train_labels) = gen_img_set(label_img_dir, df, new_dim=(h,w))\n",
        "\n",
        "\n",
        "# 2. prepare data, sampling from the original to create 5 different sets\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "X = train_imgs\n",
        "Y = train_labels\n",
        "\n",
        "# 3.prepare model\n",
        "base_model = VGG19(weights='imagenet', input_shape=list(X[0].shape),include_top=False) #set the input size to be the size of the training testing images\n",
        "fea_model= tf.keras.Model(base_model.inputs, base_model.layers[-1].output)\n",
        "\n",
        "\n",
        "# 4.train model. This will build 5 distinct models.\n",
        "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
        "    print(i, train.shape, test.shape)\n",
        "  \n",
        "    ss_train_fea=fea_model.predict(X[train])\n",
        "    ss_test_fea=fea_model.predict(X[test])\n",
        "    visible = layers.Input(shape=ss_train_fea.shape[1:])\n",
        "    \n",
        "    flat = layers.Flatten()(visible)\n",
        "    hidden = layers.Dense(units=1024, activation='relu')(flat)\n",
        "    hidden = layers.Dropout(0.5)(hidden)\n",
        "    output = layers.Dense(units=1499, activation='softmax')(hidden)\n",
        "\n",
        "    model = Model(inputs=visible, outputs=output)\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "           metrics=['accuracy']) \n",
        "\n",
        "    history_model = model.fit(ss_train_fea, np.array(Y[train]), epochs=20, batch_size=32, \n",
        "                              validation_data=(ss_test_fea, np.array(Y[test])))\n",
        "    \n",
        "    score = model.evaluate(ss_test_fea, np.array(Y[test]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3n9WzV3zczx"
      },
      "source": [
        "## Zero Rule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtko0Mzj1hFX"
      },
      "source": [
        "# Read File\n",
        "data_train_full = pd.read_csv('train.csv', sep=',')\n",
        "\n",
        "y_train_full = data_train_full['x']\n",
        "\n",
        "x_train_full = data_train_full['x']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGciXsaRzDJG"
      },
      "source": [
        "from collections import Counter\n",
        "y_zero_r_train = Counter(y_train_full).most_common()\n",
        "y_majority_class = y_zero_r_train[0][0]\n",
        "\n",
        "x_zero_r_train = Counter(x_train_full).most_common()\n",
        "x_majority_class = x_zero_r_train[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4-5m9b5XdIi"
      },
      "source": [
        "## The feature matching function\n",
        "The code of this function are from Tutorial(week 7).\n",
        "We might need to add some future extraction function to this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqPaueW2X-jR"
      },
      "source": [
        "def compare(gray,scene_gray):\n",
        "  sift = cv2.SIFT_create() # if cv2 version >= 4.4.0 \n",
        "  # sift = cv2.xfeatures2d.SIFT_create() # if cv2 version = 4.3.x \n",
        "  \n",
        "  # Compute SIFT keypoints and descriptors\n",
        "  kp1, des1 = sift.detectAndCompute(gray,None)\n",
        "  kp2, des2 = sift.detectAndCompute(scene_gray,None)\n",
        "\n",
        "  # if kp1 == [] or len(kp1)<5 or kp2 == [] or len(kp2) < 5:\n",
        "    # return 0\n",
        "\n",
        "  FLANN_INDEX_KDTREE = 1\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  search_params = dict(checks=50)   # or pass empty dictionary\n",
        "  flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "\n",
        "  # Matching descriptor using KNN algorithm\n",
        "  matches = flann.knnMatch(des1,des2,k=2)\n",
        "\n",
        "  # Create a mask to draw all good matches\n",
        "  matchesMask = []\n",
        "\n",
        "  # Store all good matches as per Lowe's Ratio test.\n",
        "  # good = []\n",
        "  good=0\n",
        "  for m,n in matches:\n",
        "    if m.distance < 0.7*n.distance:\n",
        "        # good.append(m)\n",
        "        good = good + 1\n",
        "        matchesMask.append([1,0]) # Match\n",
        "    else:\n",
        "        matchesMask.append([0,0]) # Mismatch\n",
        "       \n",
        "        \n",
        "\n",
        "  # good_matches = cv2.drawMatchesKnn(gray,kp1,scene_gray,kp2,matches,None,**draw_params)\n",
        "\n",
        "  return (good/len(matchesMask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWRxl74oBBIW"
      },
      "source": [
        "result_name = []\n",
        "\n",
        "for j in test_data_name_list:\n",
        "    k = 0\n",
        "    for i in train_data_name_list:\n",
        "        try:\n",
        "            current_result=compare(train_data[i],test_data[j])\n",
        "        except:\n",
        "            continue\n",
        "        if current_result > k:\n",
        "            k = current_result\n",
        "            current_name = i\n",
        "        else:\n",
        "            continue\n",
        "    if k == 0:\n",
        "        current_name = choice(train_data_name_list)\n",
        "    print(current_name)\n",
        "    result_name.append(current_name)\n",
        "\n",
        "\n",
        "print('result_name:',result_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prmI-SMEwpg-"
      },
      "source": [
        "# It tooks me two days to run this code\n",
        "result_names = ['IMG3628_5.jpg', 'IMG4145_4.jpg', 'IMG2757_1.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG2792_3.jpg', 'IMG3762_5.jpg', 'IMG3709_3.jpg', 'IMG2768_2.jpg', 'IMG2923_4.jpg', 'IMG3662_2.jpg', 'IMG3104_4.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3286_4.jpg', 'IMG3036_5.jpg', 'IMG3368_2.jpg', 'IMG3950_4.jpg', 'IMG3645_4.jpg', 'IMG3323_2.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG2867_2.jpg', 'IMG3232_4.jpg', 'IMG3725_1.jpg', 'IMG3036_5.jpg', 'IMG3171_2.jpg', 'IMG3845_5.jpg', 'IMG2804_2.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG2883_1.jpg', 'IMG2867_2.jpg', 'IMG3845_5.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3575_3.jpg', 'IMG3323_2.jpg', 'IMG2772_2.jpg', 'IMG3104_2.jpg', 'IMG3382_2.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3229_5.jpg', 'IMG3794_2.jpg', 'IMG3845_5.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG2845_4.jpg', 'IMG4188_1.jpg', 'IMG3323_2.jpg', 'IMG2983_2.jpg', 'IMG3880_4.jpg', 'IMG2792_3.jpg', 'IMG3721_4.jpg', 'IMG3334_2.jpg', 'IMG3753_3.jpg', 'IMG3283_4.jpg', 'IMG2800_1.jpg', 'IMG3762_5.jpg', 'IMG3709_3.jpg', 'IMG3953_2.jpg', 'IMG2817_5.jpg', 'IMG3848_3.jpg', 'IMG3502_2.jpg', 'IMG2768_2.jpg', 'IMG3343_2.jpg', 'IMG3283_4.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG2867_2.jpg', 'IMG3502_3.jpg', 'IMG3993_2.jpg', 'IMG3102_4.jpg', 'IMG2867_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3762_5.jpg', 'IMG3992_2.jpg', 'IMG3762_5.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG4145_4.jpg', 'IMG4031_5.jpg', 'IMG3420_1.jpg', 'IMG3415_1.jpg', 'IMG4145_4.jpg', 'IMG3461_2.jpg', 'IMG2907_3.jpg', 'IMG3762_5.jpg', 'IMG3323_2.jpg', 'IMG2845_4.jpg', 'IMG2746_4.jpg', 'IMG3953_2.jpg', 'IMG3149_3.jpg', 'IMG3323_2.jpg', 'IMG3874_4.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3200_4.jpg', 'IMG3368_2.jpg', 'IMG3603_1.jpg', 'IMG3323_2.jpg', 'IMG3036_5.jpg', 'IMG3028_4.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG2867_2.jpg', 'IMG3382_2.jpg', 'IMG3805_4.jpg', 'IMG3102_4.jpg', 'IMG3036_5.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG4080_3.jpg', 'IMG3502_3.jpg', 'IMG3189_3.jpg', 'IMG3072_2.jpg', 'IMG3323_2.jpg', 'IMG3164_3.jpg', 'IMG3036_5.jpg', 'IMG4196_3.jpg', 'IMG3953_2.jpg', 'IMG3867_5.jpg', 'IMG3675_4.jpg', 'IMG3880_4.jpg', 'IMG4025_1.jpg', 'IMG3794_2.jpg', 'IMG4013_1.jpg', 'IMG2772_2.jpg', 'IMG3232_4.jpg', 'IMG4183_4.jpg', 'IMG3554_2.jpg', 'IMG3232_4.jpg', 'IMG3603_5.jpg', 'IMG2867_2.jpg', 'IMG4150_2.jpg', 'IMG2772_2.jpg', 'IMG2792_3.jpg', 'IMG3848_3.jpg', 'IMG2800_5.jpg', 'IMG3794_2.jpg', 'IMG2746_4.jpg', 'IMG3828_2.jpg', 'IMG3867_5.jpg', 'IMG2867_2.jpg', 'IMG2792_3.jpg', 'IMG3232_4.jpg', 'IMG2907_3.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG3540_2.jpg', 'IMG3323_2.jpg', 'IMG3435_3.jpg', 'IMG3229_5.jpg', 'IMG4126_4.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG4168_1.jpg', 'IMG3950_4.jpg', 'IMG3232_4.jpg', 'IMG3120_1.jpg', 'IMG4013_1.jpg', 'IMG3368_2.jpg', 'IMG2784_2.jpg', 'IMG2863_2.jpg', 'IMG3582_4.jpg', 'IMG3448_5.jpg', 'IMG3953_2.jpg', 'IMG3036_5.jpg', 'IMG3120_1.jpg', 'IMG3762_5.jpg', 'IMG2863_2.jpg', 'IMG2746_2.jpg', 'IMG3415_5.jpg', 'IMG3368_2.jpg', 'IMG3368_2.jpg', 'IMG3766_3.jpg', 'IMG3154_5.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3036_5.jpg', 'IMG3383_1.jpg', 'IMG3036_5.jpg', 'IMG2867_2.jpg', 'IMG3311_2.jpg', 'IMG4141_4.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG3229_5.jpg', 'IMG3189_3.jpg', 'IMG3036_5.jpg', 'IMG3848_3.jpg', 'IMG3323_2.jpg', 'IMG3104_2.jpg', 'IMG4188_1.jpg', 'IMG3334_2.jpg', 'IMG3500_2.jpg', 'IMG3435_3.jpg', 'IMG3426_1.jpg', 'IMG3901_5.jpg', 'IMG3323_2.jpg', 'IMG3709_3.jpg', 'IMG3229_5.jpg', 'IMG2867_2.jpg', 'IMG3323_2.jpg', 'IMG3845_5.jpg', 'IMG3232_4.jpg', 'IMG3179_5.jpg', 'IMG4130_1.jpg', 'IMG3232_4.jpg', 'IMG3232_4.jpg', 'IMG3232_4.jpg', 'IMG2772_2.jpg', 'IMG3794_2.jpg', 'IMG3448_5.jpg', 'IMG4149_3.jpg', 'IMG3762_5.jpg', 'IMG3232_4.jpg', 'IMG3794_2.jpg', 'IMG2800_1.jpg', 'IMG4188_1.jpg', 'IMG3880_4.jpg', 'IMG2867_2.jpg', 'IMG3334_2.jpg', 'IMG3232_4.jpg', 'IMG3762_5.jpg', 'IMG3415_1.jpg', 'IMG4067_5.jpg', 'IMG4145_4.jpg', 'IMG3435_3.jpg', 'IMG3896_1.jpg', 'IMG3357_4.jpg', 'IMG2867_2.jpg', 'IMG3036_5.jpg', 'IMG3323_2.jpg', 'IMG3229_5.jpg', 'IMG2845_4.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG3036_5.jpg', 'IMG3036_5.jpg', 'IMG2914_2.jpg', 'IMG3582_4.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3934_1.jpg', 'IMG3575_3.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG3848_3.jpg', 'IMG3323_2.jpg', 'IMG2768_2.jpg', 'IMG3334_2.jpg', 'IMG2854_5.jpg', 'IMG3334_2.jpg', 'IMG2746_2.jpg', 'IMG3200_4.jpg', 'IMG3368_2.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3036_5.jpg', 'IMG3621_2.jpg', 'IMG3874_4.jpg', 'IMG3164_3.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG4145_4.jpg', 'IMG3104_4.jpg', 'IMG3036_5.jpg', 'IMG2929_1.jpg', 'IMG3603_5.jpg', 'IMG2867_2.jpg', 'IMG3323_2.jpg', 'IMG3950_4.jpg', 'IMG3686_4.jpg', 'IMG3323_2.jpg', 'IMG3200_4.jpg', 'IMG2792_3.jpg', 'IMG2768_2.jpg', 'IMG3323_2.jpg', 'IMG3725_1.jpg', 'IMG2803_5.jpg', 'IMG3200_4.jpg', 'IMG2887_4.jpg', 'IMG3368_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG2768_2.jpg', 'IMG2816_2.jpg', 'IMG3603_5.jpg', 'IMG2746_2.jpg', 'IMG3845_5.jpg', 'IMG3357_4.jpg', 'IMG3368_2.jpg', 'IMG4226_3.jpg', 'IMG3334_2.jpg', 'IMG3845_5.jpg', 'IMG3196_3.jpg', 'IMG4001_4.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3885_4.jpg', 'IMG3323_2.jpg', 'IMG3149_3.jpg', 'IMG3357_4.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3379_1.jpg', 'IMG3747_4.jpg', 'IMG3451_5.jpg', 'IMG3104_2.jpg', 'IMG3368_2.jpg', 'IMG4145_4.jpg', 'IMG3950_4.jpg', 'IMG3323_2.jpg', 'IMG2867_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3709_3.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3420_1.jpg', 'IMG3334_2.jpg', 'IMG3502_2.jpg', 'IMG4234_5.jpg', 'IMG3575_3.jpg', 'IMG2863_2.jpg', 'IMG3323_2.jpg', 'IMG3603_5.jpg', 'IMG3104_4.jpg', 'IMG2867_2.jpg', 'IMG2792_3.jpg', 'IMG3762_5.jpg', 'IMG2903_4.jpg', 'IMG4196_3.jpg', 'IMG3323_2.jpg', 'IMG3828_2.jpg', 'IMG3229_5.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3323_2.jpg', 'IMG3762_5.jpg', 'IMG3287_5.jpg', 'IMG3334_2.jpg', 'IMG3368_2.jpg', 'IMG3164_1.jpg', 'IMG3323_2.jpg', 'IMG2772_2.jpg', 'IMG2788_4.jpg', 'IMG3334_2.jpg', 'IMG3896_1.jpg', 'IMG3725_1.jpg', 'IMG4107_3.jpg', 'IMG3164_3.jpg', 'IMG2867_2.jpg', 'IMG2772_2.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG4150_2.jpg', 'IMG3323_2.jpg', 'IMG3845_5.jpg', 'IMG3502_2.jpg', 'IMG2804_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG2883_1.jpg', 'IMG3164_3.jpg', 'IMG3323_2.jpg', 'IMG3692_4.jpg', 'IMG3323_2.jpg', 'IMG2867_2.jpg', 'IMG3323_2.jpg', 'IMG3725_1.jpg', 'IMG4130_1.jpg', 'IMG3036_5.jpg', 'IMG3323_2.jpg', 'IMG3415_1.jpg', 'IMG3171_2.jpg', 'IMG2883_1.jpg', 'IMG3323_2.jpg', 'IMG3845_5.jpg', 'IMG2903_4.jpg', 'IMG3725_1.jpg', 'IMG3323_2.jpg', 'IMG3958_5.jpg', 'IMG3420_1.jpg', 'IMG3575_3.jpg', 'IMG3845_5.jpg', 'IMG3334_2.jpg', 'IMG3077_3.jpg', 'IMG3036_5.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3232_4.jpg', 'IMG3311_2.jpg', 'IMG3420_1.jpg', 'IMG3382_2.jpg', 'IMG3323_2.jpg', 'IMG3645_4.jpg', 'IMG2792_3.jpg', 'IMG3727_2.jpg', 'IMG3232_4.jpg', 'IMG3953_2.jpg', 'IMG2882_2.jpg', 'IMG2863_2.jpg', 'IMG3232_4.jpg', 'IMG3845_5.jpg', 'IMG3323_2.jpg', 'IMG4234_5.jpg', 'IMG3068_3.jpg', 'IMG3334_2.jpg', 'IMG3762_5.jpg', 'IMG3382_2.jpg', 'IMG3992_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3709_3.jpg', 'IMG3323_2.jpg', 'IMG4150_2.jpg', 'IMG3120_1.jpg', 'IMG3645_4.jpg', 'IMG4130_1.jpg', 'IMG3577_3.jpg', 'IMG2964_3.jpg', 'IMG2768_2.jpg', 'IMG3382_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG2792_3.jpg', 'IMG3373_3.jpg', 'IMG3323_2.jpg', 'IMG3036_5.jpg', 'IMG3500_2.jpg', 'IMG3323_2.jpg', 'IMG3582_4.jpg', 'IMG3950_4.jpg', 'IMG3200_4.jpg', 'IMG3323_2.jpg', 'IMG3709_3.jpg', 'IMG3323_2.jpg', 'IMG3405_4.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG2975_5.jpg', 'IMG2817_5.jpg', 'IMG2792_3.jpg', 'IMG2772_2.jpg', 'IMG3366_1.jpg', 'IMG2782_5.jpg', 'IMG3368_2.jpg', 'IMG4116_5.jpg', 'IMG3762_5.jpg', 'IMG2845_4.jpg', 'IMG3725_1.jpg', 'IMG3992_2.jpg', 'IMG3323_2.jpg', 'IMG3848_3.jpg', 'IMG3243_1.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG2867_2.jpg', 'IMG3794_2.jpg', 'IMG3762_5.jpg', 'IMG2768_2.jpg', 'IMG3323_2.jpg', 'IMG2792_3.jpg', 'IMG3603_5.jpg', 'IMG3681_5.jpg', 'IMG3911_4.jpg', 'IMG3323_2.jpg', 'IMG3582_4.jpg', 'IMG3323_2.jpg', 'IMG3036_5.jpg', 'IMG4168_1.jpg', 'IMG3052_3.jpg', 'IMG3794_2.jpg', 'IMG4203_3.jpg', 'IMG3435_3.jpg', 'IMG3468_2.jpg', 'IMG2772_2.jpg', 'IMG3323_2.jpg', 'IMG2927_3.jpg', 'IMG3953_2.jpg', 'IMG4196_3.jpg', 'IMG3323_2.jpg', 'IMG3420_1.jpg', 'IMG3794_2.jpg', 'IMG3848_3.jpg', 'IMG3323_2.jpg', 'IMG2867_2.jpg', 'IMG3848_3.jpg', 'IMG3171_2.jpg', 'IMG4198_3.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG4234_5.jpg', 'IMG3229_5.jpg', 'IMG3415_1.jpg', 'IMG3036_5.jpg', 'IMG3709_3.jpg', 'IMG3382_2.jpg', 'IMG2768_2.jpg', 'IMG3753_3.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG3283_4.jpg', 'IMG2914_2.jpg', 'IMG4153_1.jpg', 'IMG2802_1.jpg', 'IMG2929_1.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG2768_2.jpg', 'IMG3816_4.jpg', 'IMG3766_3.jpg', 'IMG3615_2.jpg', 'IMG3961_4.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3247_2.jpg', 'IMG4150_2.jpg', 'IMG3232_4.jpg', 'IMG3229_5.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3645_4.jpg', 'IMG3323_2.jpg', 'IMG2863_2.jpg', 'IMG3304_3.jpg', 'IMG3334_2.jpg', 'IMG3247_2.jpg', 'IMG3323_2.jpg', 'IMG3709_3.jpg', 'IMG3368_2.jpg', 'IMG3953_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3719_4.jpg', 'IMG3665_3.jpg', 'IMG3334_2.jpg', 'IMG3068_3.jpg', 'IMG3762_5.jpg', 'IMG3232_4.jpg', 'IMG3794_2.jpg', 'IMG3575_3.jpg', 'IMG2975_5.jpg', 'IMG3323_2.jpg', 'IMG2928_5.jpg', 'IMG3762_5.jpg', 'IMG3738_3.jpg', 'IMG2768_2.jpg', 'IMG3901_5.jpg', 'IMG3171_2.jpg', 'IMG3738_3.jpg', 'IMG3060_5.jpg', 'IMG3334_2.jpg', 'IMG3232_4.jpg', 'IMG3048_1.jpg', 'IMG3323_2.jpg', 'IMG3154_5.jpg', 'IMG3380_2.jpg', 'IMG2879_5.jpg', 'IMG3171_2.jpg', 'IMG3243_1.jpg', 'IMG2923_4.jpg', 'IMG3232_4.jpg', 'IMG4145_4.jpg', 'IMG3247_2.jpg', 'IMG3845_5.jpg', 'IMG3368_2.jpg', 'IMG3323_2.jpg', 'IMG3229_5.jpg', 'IMG3247_2.jpg', 'IMG3120_1.jpg', 'IMG3164_3.jpg', 'IMG4226_3.jpg', 'IMG3323_2.jpg', 'IMG3575_3.jpg', 'IMG3323_2.jpg', 'IMG3575_3.jpg', 'IMG2927_3.jpg', 'IMG3317_1.jpg', 'IMG3323_2.jpg', 'IMG3171_2.jpg', 'IMG3540_2.jpg', 'IMG3773_1.jpg', 'IMG2845_4.jpg', 'IMG4142_5.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG4107_3.jpg', 'IMG3845_5.jpg', 'IMG2867_2.jpg', 'IMG3066_3.jpg', 'IMG2784_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG2888_2.jpg', 'IMG3845_5.jpg', 'IMG3120_1.jpg', 'IMG3036_5.jpg', 'IMG3232_4.jpg', 'IMG2923_4.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3229_5.jpg', 'IMG4025_1.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3104_2.jpg', 'IMG3323_2.jpg', 'IMG3934_1.jpg', 'IMG3880_4.jpg', 'IMG3794_2.jpg', 'IMG4145_4.jpg', 'IMG3625_2.jpg', 'IMG3368_2.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG2928_5.jpg', 'IMG2964_3.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3232_4.jpg', 'IMG3311_2.jpg', 'IMG3828_2.jpg', 'IMG2902_1.jpg', 'IMG3368_2.jpg', 'IMG3334_2.jpg', 'IMG3164_3.jpg', 'IMG3386_2.jpg', 'IMG3366_1.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG2867_2.jpg', 'IMG2902_1.jpg', 'IMG3154_5.jpg', 'IMG3323_2.jpg', 'IMG3036_5.jpg', 'IMG3762_5.jpg', 'IMG3036_5.jpg', 'IMG3556_2.jpg', 'IMG3874_4.jpg', 'IMG4053_1.jpg', 'IMG2867_2.jpg', 'IMG3845_5.jpg', 'IMG4145_4.jpg', 'IMG3597_2.jpg', 'IMG3794_2.jpg', 'IMG2975_5.jpg', 'IMG2786_4.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3404_2.jpg', 'IMG3323_2.jpg', 'IMG3582_4.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG2867_2.jpg', 'IMG4025_1.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG3762_5.jpg', 'IMG2928_5.jpg', 'IMG3323_2.jpg', 'IMG4145_4.jpg', 'IMG3999_3.jpg', 'IMG3323_2.jpg', 'IMG3540_2.jpg', 'IMG3415_1.jpg', 'IMG3229_5.jpg', 'IMG3323_2.jpg', 'IMG3368_2.jpg', 'IMG3848_3.jpg', 'IMG3232_4.jpg', 'IMG3738_3.jpg', 'IMG3323_2.jpg', 'IMG3603_5.jpg', 'IMG3036_5.jpg', 'IMG3171_2.jpg', 'IMG3077_3.jpg', 'IMG3575_3.jpg', 'IMG3738_3.jpg', 'IMG2929_1.jpg', 'IMG3036_5.jpg', 'IMG3845_5.jpg', 'IMG3334_2.jpg', 'IMG2867_2.jpg', 'IMG3950_4.jpg', 'IMG3323_2.jpg', 'IMG2792_3.jpg', 'IMG4025_1.jpg', 'IMG4137_2.jpg', 'IMG3323_2.jpg', 'IMG4130_1.jpg', 'IMG3575_3.jpg', 'IMG3323_2.jpg', 'IMG2768_2.jpg', 'IMG3164_1.jpg', 'IMG3120_1.jpg', 'IMG2902_1.jpg', 'IMG3229_5.jpg', 'IMG3323_2.jpg', 'IMG3248_1.jpg', 'IMG3323_2.jpg', 'IMG3247_2.jpg', 'IMG3323_2.jpg', 'IMG2768_2.jpg', 'IMG4141_4.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3057_3.jpg', 'IMG3036_5.jpg', 'IMG2792_3.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3104_2.jpg', 'IMG2867_2.jpg', 'IMG3334_2.jpg', 'IMG2867_2.jpg', 'IMG2919_4.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3248_1.jpg', 'IMG3129_5.jpg', 'IMG4198_3.jpg', 'IMG3415_1.jpg', 'IMG3283_4.jpg', 'IMG3762_5.jpg', 'IMG3323_2.jpg', 'IMG4150_2.jpg', 'IMG3762_5.jpg', 'IMG3334_2.jpg', 'IMG3232_4.jpg', 'IMG3709_3.jpg', 'IMG3794_2.jpg', 'IMG4234_5.jpg', 'IMG3575_3.jpg', 'IMG3232_4.jpg', 'IMG3334_2.jpg', 'IMG3368_2.jpg', 'IMG3028_4.jpg', 'IMG2883_1.jpg', 'IMG3323_2.jpg', 'IMG3500_2.jpg', 'IMG3215_1.jpg', 'IMG4150_2.jpg', 'IMG3368_2.jpg', 'IMG3415_1.jpg', 'IMG3794_2.jpg', 'IMG3317_1.jpg', 'IMG3070_2.jpg', 'IMG3794_2.jpg', 'IMG3232_4.jpg', 'IMG2792_3.jpg', 'IMG2792_3.jpg', 'IMG2772_2.jpg', 'IMG2768_2.jpg', 'IMG2772_2.jpg', 'IMG3848_3.jpg', 'IMG3893_3.jpg', 'IMG3048_1.jpg', 'IMG3036_5.jpg', 'IMG3645_4.jpg', 'IMG3323_2.jpg', 'IMG3603_5.jpg', 'IMG3154_5.jpg', 'IMG3323_2.jpg', 'IMG3738_3.jpg', 'IMG3334_2.jpg', 'IMG3334_2.jpg', 'IMG3028_1.jpg', 'IMG3334_2.jpg', 'IMG3845_5.jpg', 'IMG3848_3.jpg', 'IMG3251_3.jpg', 'IMG2804_2.jpg', 'IMG3028_1.jpg', 'IMG3323_2.jpg', 'IMG3762_5.jpg', 'IMG3323_2.jpg', 'IMG2894_1.jpg', 'IMG3036_5.jpg', 'IMG3603_5.jpg', 'IMG3323_2.jpg', 'IMG3036_5.jpg', 'IMG3280_1.jpg', 'IMG3502_2.jpg', 'IMG3088_3.jpg', 'IMG4196_3.jpg', 'IMG3794_2.jpg', 'IMG3323_2.jpg', 'IMG3415_1.jpg', 'IMG4203_3.jpg', 'IMG3645_4.jpg', 'IMG3323_2.jpg', 'IMG3468_2.jpg', 'IMG3950_4.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG3953_2.jpg', 'IMG3232_4.jpg', 'IMG3911_4.jpg', 'IMG3725_1.jpg', 'IMG2923_4.jpg', 'IMG3845_5.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3171_2.jpg', 'IMG3232_4.jpg', 'IMG3368_2.jpg', 'IMG4183_4.jpg', 'IMG4150_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3725_1.jpg', 'IMG2803_5.jpg', 'IMG3334_2.jpg', 'IMG3549_4.jpg', 'IMG3794_2.jpg', 'IMG2768_2.jpg', 'IMG4149_5.jpg', 'IMG4141_4.jpg', 'IMG3645_4.jpg', 'IMG2802_1.jpg', 'IMG2975_5.jpg', 'IMG3794_2.jpg', 'IMG3738_3.jpg', 'IMG3323_2.jpg', 'IMG2914_2.jpg', 'IMG4186_4.jpg', 'IMG3224_2.jpg', 'IMG3415_1.jpg', 'IMG3588_1.jpg', 'IMG3621_2.jpg', 'IMG3248_1.jpg', 'IMG3961_4.jpg', 'IMG3323_2.jpg', 'IMG3036_5.jpg', 'IMG3164_3.jpg', 'IMG4150_2.jpg', 'IMG3323_2.jpg', 'IMG3845_5.jpg', 'IMG3575_3.jpg', 'IMG3615_2.jpg', 'IMG2792_3.jpg', 'IMG3435_3.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3958_5.jpg', 'IMG3311_2.jpg', 'IMG3247_2.jpg', 'IMG3334_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG4013_1.jpg', 'IMG4109_4.jpg', 'IMG3308_4.jpg', 'IMG3232_4.jpg', 'IMG4007_4.jpg', 'IMG3068_3.jpg', 'IMG4150_2.jpg', 'IMG4150_2.jpg', 'IMG3323_2.jpg', 'IMG3958_5.jpg', 'IMG2802_1.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3725_1.jpg', 'IMG2792_3.jpg', 'IMG2792_3.jpg', 'IMG3368_2.jpg', 'IMG3762_5.jpg', 'IMG4013_1.jpg', 'IMG3763_3.jpg', 'IMG3323_2.jpg', 'IMG3847_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3415_1.jpg', 'IMG3848_3.jpg', 'IMG2800_1.jpg', 'IMG3323_2.jpg', 'IMG3845_5.jpg', 'IMG3141_4.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG3232_4.jpg', 'IMG3028_1.jpg', 'IMG4168_1.jpg', 'IMG3334_2.jpg', 'IMG3154_5.jpg', 'IMG3958_5.jpg', 'IMG3373_3.jpg', 'IMG2867_2.jpg', 'IMG3323_2.jpg', 'IMG2867_2.jpg', 'IMG3813_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3709_3.jpg', 'IMG3323_2.jpg', 'IMG3048_1.jpg', 'IMG3435_3.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3366_1.jpg', 'IMG4234_5.jpg', 'IMG3294_5.jpg', 'IMG3334_2.jpg', 'IMG3597_2.jpg', 'IMG2803_5.jpg', 'IMG3036_5.jpg', 'IMG3575_3.jpg', 'IMG2772_2.jpg', 'IMG4198_3.jpg', 'IMG3077_3.jpg', 'IMG3232_4.jpg', 'IMG2914_2.jpg', 'IMG3845_5.jpg', 'IMG3368_2.jpg', 'IMG3334_2.jpg', 'IMG3129_5.jpg', 'IMG3323_2.jpg', 'IMG2924_4.jpg', 'IMG3784_5.jpg', 'IMG3334_2.jpg', 'IMG2772_2.jpg', 'IMG3251_3.jpg', 'IMG3725_1.jpg', 'IMG3247_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG2768_2.jpg', 'IMG3794_2.jpg', 'IMG3709_3.jpg', 'IMG3334_2.jpg', 'IMG3036_5.jpg', 'IMG3368_2.jpg', 'IMG2768_2.jpg', 'IMG3597_2.jpg', 'IMG2923_4.jpg', 'IMG3334_2.jpg', 'IMG3223_3.jpg', 'IMG3418_3.jpg', 'IMG3149_3.jpg', 'IMG3323_2.jpg', 'IMG3593_1.jpg', 'IMG3934_1.jpg', 'IMG2867_2.jpg', 'IMG3232_4.jpg', 'IMG3048_1.jpg', 'IMG3036_5.jpg', 'IMG3323_2.jpg', 'IMG3953_2.jpg', 'IMG3794_2.jpg', 'IMG2928_5.jpg', 'IMG3323_2.jpg', 'IMG2943_2.jpg', 'IMG3575_3.jpg', 'IMG2999_3.jpg', 'IMG3368_2.jpg', 'IMG3738_3.jpg', 'IMG4188_1.jpg', 'IMG3334_2.jpg', 'IMG3248_1.jpg', 'IMG3413_2.jpg', 'IMG3283_4.jpg', 'IMG3762_5.jpg', 'IMG3189_3.jpg', 'IMG3709_3.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3645_4.jpg', 'IMG3582_4.jpg', 'IMG2923_4.jpg', 'IMG3404_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG2792_3.jpg', 'IMG3218_3.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG3149_3.jpg', 'IMG4149_5.jpg', 'IMG4117_2.jpg', 'IMG3036_5.jpg', 'IMG3334_2.jpg', 'IMG3415_1.jpg', 'IMG4117_2.jpg', 'IMG3323_2.jpg', 'IMG2817_5.jpg', 'IMG3645_4.jpg', 'IMG2845_4.jpg', 'IMG3334_2.jpg', 'IMG3992_2.jpg', 'IMG3323_2.jpg', 'IMG4186_4.jpg', 'IMG2802_1.jpg', 'IMG3323_2.jpg', 'IMG3502_2.jpg', 'IMG3828_2.jpg', 'IMG3415_1.jpg', 'IMG3854_1.jpg', 'IMG4014_5.jpg', 'IMG3368_2.jpg', 'IMG3286_4.jpg', 'IMG4188_1.jpg', 'IMG3323_2.jpg', 'IMG3727_2.jpg', 'IMG3076_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3721_4.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3334_2.jpg', 'IMG3232_4.jpg', 'IMG3088_2.jpg', 'IMG3721_4.jpg', 'IMG3243_1.jpg', 'IMG2787_3.jpg', 'IMG3934_1.jpg', 'IMG3323_2.jpg', 'IMG3899_1.jpg', 'IMG3500_2.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG3502_2.jpg', 'IMG3681_5.jpg', 'IMG3999_3.jpg', 'IMG3323_2.jpg', 'IMG3864_3.jpg', 'IMG2867_2.jpg', 'IMG3822_1.jpg', 'IMG2927_3.jpg', 'IMG3794_2.jpg', 'IMG3420_1.jpg', 'IMG3848_3.jpg', 'IMG3232_4.jpg', 'IMG3323_2.jpg', 'IMG2914_2.jpg', 'IMG4212_3.jpg', 'IMG3323_2.jpg', 'IMG4168_1.jpg', 'IMG2902_1.jpg', 'IMG3234_1.jpg', 'IMG3323_2.jpg', 'IMG3794_2.jpg', 'IMG3247_2.jpg', 'IMG3283_4.jpg', 'IMG3415_1.jpg', 'IMG2867_2.jpg', 'IMG3380_2.jpg', 'IMG4150_2.jpg', 'IMG3662_2.jpg', 'IMG3323_2.jpg', 'IMG4126_4.jpg', 'IMG3762_5.jpg', 'IMG2914_2.jpg', 'IMG3036_5.jpg', 'IMG2746_2.jpg', 'IMG2792_3.jpg', 'IMG2768_2.jpg', 'IMG3171_2.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3549_4.jpg', 'IMG3183_4.jpg', 'IMG3334_2.jpg', 'IMG3036_5.jpg', 'IMG2792_3.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG2919_4.jpg', 'IMG3762_5.jpg', 'IMG3413_2.jpg', 'IMG3129_5.jpg', 'IMG3323_2.jpg', 'IMG3762_5.jpg', 'IMG4126_4.jpg', 'IMG2873_3.jpg', 'IMG3582_4.jpg', 'IMG2800_1.jpg', 'IMG3681_5.jpg', 'IMG3383_1.jpg', 'IMG3334_2.jpg', 'IMG4090_1.jpg', 'IMG3334_2.jpg', 'IMG3283_4.jpg', 'IMG4194_2.jpg', 'IMG3323_2.jpg', 'IMG3461_2.jpg', 'IMG2867_2.jpg', 'IMG3845_5.jpg', 'IMG3334_2.jpg', 'IMG3036_5.jpg', 'IMG4053_1.jpg', 'IMG4001_4.jpg', 'IMG3794_2.jpg', 'IMG3848_3.jpg', 'IMG3575_3.jpg', 'IMG3232_4.jpg', 'IMG2863_2.jpg', 'IMG3232_4.jpg', 'IMG3036_5.jpg', 'IMG3057_3.jpg', 'IMG3323_2.jpg', 'IMG3762_5.jpg', 'IMG3232_4.jpg', 'IMG4153_1.jpg', 'IMG3323_2.jpg', 'IMG2929_1.jpg', 'IMG4230_4.jpg', 'IMG3323_2.jpg', 'IMG3189_3.jpg', 'IMG3845_5.jpg', 'IMG3794_2.jpg', 'IMG3490_1.jpg', 'IMG3323_2.jpg', 'IMG4013_1.jpg', 'IMG2792_3.jpg', 'IMG3500_2.jpg', 'IMG3323_2.jpg', 'IMG4145_4.jpg', 'IMG3232_4.jpg', 'IMG3247_2.jpg', 'IMG3378_3.jpg', 'IMG3880_4.jpg', 'IMG3603_5.jpg', 'IMG3794_2.jpg', 'IMG4025_1.jpg', 'IMG3232_4.jpg', 'IMG3768_4.jpg', 'IMG2782_5.jpg', 'IMG3366_1.jpg', 'IMG3582_4.jpg', 'IMG3287_5.jpg', 'IMG3368_2.jpg', 'IMG3323_2.jpg', 'IMG3575_3.jpg', 'IMG3113_1.jpg', 'IMG3200_4.jpg', 'IMG2879_5.jpg', 'IMG2772_2.jpg', 'IMG3950_4.jpg', 'IMG3323_2.jpg', 'IMG3992_2.jpg', 'IMG3911_4.jpg', 'IMG3323_2.jpg', 'IMG3323_2.jpg', 'IMG3500_2.jpg', 'IMG2999_3.jpg', 'IMG3334_2.jpg', 'IMG3036_5.jpg', 'IMG4090_1.jpg', 'IMG3597_2.jpg', 'IMG3323_2.jpg', 'IMG4141_4.jpg', 'IMG3070_2.jpg', 'IMG3171_2.jpg', 'IMG2952_4.jpg', 'IMG3593_1.jpg', 'IMG3415_1.jpg', 'IMG2888_2.jpg', 'IMG3575_3.jpg', 'IMG3382_2.jpg', 'IMG3420_1.jpg', 'IMG3334_2.jpg', 'IMG3323_2.jpg', 'IMG3603_5.jpg', 'IMG3323_2.jpg', 'IMG3992_2.jpg', 'IMG3762_5.jpg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrxzlRZPwzrj"
      },
      "source": [
        "# Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wIKYCRdO29"
      },
      "source": [
        "# Codes from Tutorial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxWCz45hw7Bb"
      },
      "source": [
        "import pixellib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVDg-KjGZb6B"
      },
      "source": [
        "from pixellib.semantic import semantic_segmentation\n",
        "\n",
        "# Created an instance of semantic segmentation class\n",
        "segment_image = semantic_segmentation()\n",
        "\n",
        "# Call the function to load the xception model trained on pascal voc.\n",
        "segment_image.load_pascalvoc_model(\"deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\") \n",
        "\n",
        "# Performs segmentation on an image and the segmentation is done in the pascalvoc's color format.\n",
        "segment_image.segmentAsPascalvoc(\"sample4.jpg\", output_image_name = \"output.jpg\")\n",
        "# Obtain an image with segmentation overlay on the objects by setting overlay = True\n",
        "segment_image.segmentAsPascalvoc(\"sample4.jpg\", output_image_name = \"overlap.jpg\", overlay = True)\n",
        "\n",
        "\n",
        "# Display the results\n",
        "# Read an image into BGR Format and Convert to RGB\n",
        "img = cv2.cvtColor(cv2.imread('sample4.jpg'),cv2.COLOR_BGR2RGB)\n",
        "img1 = cv2.cvtColor(cv2.imread('output.jpg'),cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(cv2.imread('overlap.jpg'),cv2.COLOR_BGR2RGB)\n",
        "# Plot them out\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(3,1,1),plt.imshow(img)\n",
        "plt.title(\"Original Image\"), plt.axis('off')\n",
        "plt.subplot(3,1,2),plt.imshow(img1)\n",
        "plt.title('Semantic Segmentation Result'), plt.axis('off')\n",
        "plt.subplot(3,1,3),plt.imshow(img2)\n",
        "plt.title('Image with Segmentation Overlay'), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbYc9kJlZwWk"
      },
      "source": [
        "# Average Hash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNlNCMhTi3Mn"
      },
      "source": [
        "# code from: https://pypi.org/project/ImageHash/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlbr76OVcOS9"
      },
      "source": [
        "from PIL import Image\n",
        "import imagehash\n",
        "import os\n",
        "def compare2(train_data_name_list,test_data_name_list):\n",
        "  result_name_list = []\n",
        "  for test_data_name in test_data_name_list:\n",
        "    k=0\n",
        "    for train_data_name in train_data_name_list:\n",
        "      #use the build in function average_hash\n",
        "      a_hash = imagehash.average_hash(Image.open('./train'+'/'+train_data_name))\n",
        "      b_hash = imagehash.average_hash(Image.open('./test'+'/'+test_data_name))\n",
        "      if abs(a_hash - b_hash) > k:\n",
        "        k = abs(a_hash - b_hash)\n",
        "        current_name = train_data_name\n",
        "      else:\n",
        "        continue\n",
        "    print(current_name)\n",
        "    result_name_list.append(current_name)\n",
        "  print('result_name:',result_name_list)\n",
        "  return result_name_list\n",
        "\n",
        "# print(a_hash - b_hash)\n",
        "train_data_name_list = os.listdir('./train/')#[:3000]\n",
        "test_data_name_list = os.listdir('./test/')#[:20]\n",
        "compare2(train_data_name_list,test_data_name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DqzIj7LcR5v"
      },
      "source": [
        "# Perceptron Hash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xTr3fUgcVjv"
      },
      "source": [
        "from PIL import Image\n",
        "import imagehash\n",
        "import os\n",
        "\n",
        "def compare2(train_data_name_list,test_data_name_list):\n",
        "  result_name_list = []\n",
        "  for test_data_name in test_data_name_list:\n",
        "    k=0\n",
        "    for train_data_name in train_data_name_list:\n",
        "      hash1 = imagehash.phash(Image.open('./train'+'/'+train_data_name))\n",
        "      hash2 = imagehash.phash(Image.open('./test'+'/'+test_data_name))\n",
        "      if 1 - (hash1 - hash2)/len(hash1.hash)**2 > k:\n",
        "        k = 1 - (hash1 - hash2)/len(hash1.hash)**2\n",
        "        current_name = train_data_name\n",
        "      else:\n",
        "        continue\n",
        "    print(current_name)\n",
        "    result_name_list.append(current_name)\n",
        "  print('result_name:',result_name_list)\n",
        "  return result_name_list\n",
        "\n",
        "train_data_name_list = os.listdir('./train/')#[:3000]\n",
        "test_data_name_list = os.listdir('./test/')#[:20]\n",
        "compare2(train_data_name_list,test_data_name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv-sjIq-y1l8"
      },
      "source": [
        "# Compute similarity for the feature matching method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtxYV_4yy98e"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from operator import itemgetter \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "# 1. prepare image sets\n",
        "## (1).load labelled images\n",
        "label_img_fnames = list(os.listdir(label_img_dir)) # the grader should define the list by self.\n",
        "train_img_names = [fname.split('.')[0] for fname in label_img_fnames]\n",
        "train_imgs = []\n",
        "for names in train_img_names:\n",
        "    img = cv2.imread(os.path.join(label_img_dir, f'{names}.jpg'))\n",
        "    img = cv2.resize(img, (w, h), interpolation = cv2.INTER_AREA)\n",
        "    train_imgs.append(img)\n",
        "train_imgs = np.array(train_imgs)\n",
        "\n",
        "\n",
        "## (2).load unlabelled images \n",
        "unlabel_img_fnames = list(os.listdir(unlabel_img_dir)) # the grader should define the list by self.\n",
        "pred_img_names = [fname.split('.')[0] for fname in unlabel_img_fnames]\n",
        "pred_imgs = []\n",
        "for names in pred_img_names:\n",
        "    img = cv2.imread(os.path.join(unlabel_img_dir, f'{names}.jpg'))\n",
        "    img = cv2.resize(img, (w, h), interpolation = cv2.INTER_AREA)\n",
        "    pred_imgs.append(img)\n",
        "pred_imgs = np.array(pred_imgs)\n",
        "\n",
        "\n",
        "# 2.prepare the feature extractor\n",
        "X_train = train_imgs\n",
        "X_pred = pred_imgs\n",
        "\n",
        "img_shape = list(X_train[0].shape[1:])  # the shape of input image. \n",
        "base_model = VGG19(weights='imagenet', input_shape=img_shape, include_top=False)\n",
        "fea_model= tf.keras.Model(base_model.inputs, base_model.layers[-1].output)\n",
        "\n",
        "ss_train_fea = fea_model.predict(X_train)\n",
        "ss_pred_fea = fea_model.predict(X_pred)\n",
        "\n",
        "# compute the mean square error\n",
        "# the output shape will be : 1200 x 7500\n",
        "res = []\n",
        "for i, pred_img in enumerate(ss_pred_fea):\n",
        "    A = pred_img.flatten()\n",
        "    mses = []\n",
        "    for j, train_img in enumerate(ss_train_fea):\n",
        "        B = train_img.flatten()\n",
        "        mse = np.square(A-B).mean(axis=None)\n",
        "        mses.append(mse)\n",
        "    res.append(mses)\n",
        "\n",
        "\n",
        "# sort and select the 10 most similar objects\n",
        "# the shape of ans will be 1200 x 10. \n",
        "# key is file name for a unlabelled image, \n",
        "# value is a list of candidate of 10 images from the labelled image set.\n",
        "ans = dict()\n",
        "rank = 10\n",
        "for idx, row in enumerate(res):\n",
        "    indices = sorted(range(len(row)), key=row.__getitem__)[:rank]\n",
        "    ans[pred_img_names[idx]] = [fname for fname in itemgetter(*indices)(train_img_names)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyitLMq2Ll4d"
      },
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "# Convert dictonary to Dataframe\n",
        "ans = pd.DataFrame.from_dict(ans,orient='index')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIbRHhoCJ5R3"
      },
      "source": [
        "def compare(gray,scene_gray):\n",
        "  sift = cv2.SIFT_create() # if cv2 version >= 4.4.0 \n",
        "  # sift = cv2.xfeatures2d.SIFT_create() # if cv2 version = 4.3.x \n",
        "  \n",
        "  # Compute SIFT keypoints and descriptors\n",
        "  kp1, des1 = sift.detectAndCompute(gray,None)\n",
        "  kp2, des2 = sift.detectAndCompute(scene_gray,None)\n",
        "\n",
        "  # if kp1 == [] or len(kp1)<5 or kp2 == [] or len(kp2) < 5:\n",
        "    # return 0\n",
        "\n",
        "  FLANN_INDEX_KDTREE = 1\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  search_params = dict(checks=50)   # or pass empty dictionary\n",
        "  flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "\n",
        "  # Matching descriptor using KNN algorithm\n",
        "  matches = flann.knnMatch(des1,des2,k=2)\n",
        "\n",
        "  # Create a mask to draw all good matches\n",
        "  matchesMask = []\n",
        "\n",
        "  # Store all good matches as per Lowe's Ratio test.\n",
        "  # good = []\n",
        "  good=0\n",
        "  for m,n in matches:\n",
        "    if m.distance < 0.7*n.distance:\n",
        "        # good.append(m)\n",
        "        good = good + 1\n",
        "        matchesMask.append([1,0]) # Match\n",
        "    else:\n",
        "        matchesMask.append([0,0]) # Mismatch\n",
        "       \n",
        "        \n",
        "\n",
        "  return (good/len(matchesMask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1LbeZs9J5R9"
      },
      "source": [
        "# output_csv = pd.read_csv('./output.csv')\n",
        "\n",
        "test_csv = ans\n",
        "\n",
        "test_data_name_list = test_csv['pred_img_name'].values.tolist()\n",
        "\n",
        "result_name = []\n",
        "\n",
        "for j in test_data_name_list:\n",
        "    k = 0\n",
        "    train_data_name_list = ast.literal_eval(test_csv.loc[test_csv['pred_img_name'] == j]['train_img_names'].tolist()[0])\n",
        "    #print('train_data_name_list:', train_data_name_list)\n",
        "    for i in train_data_name_list:\n",
        "        try:\n",
        "            current_result=compare('/home/kali/Documents/Computer Vision/Project/train/' + i + '.jpg', '/home/kali/Documents/Computer Vision/Project/test/' + j + '.jpg')\n",
        "        except:\n",
        "            continue\n",
        "        if current_result > k:\n",
        "            k = current_result\n",
        "            current_name = i\n",
        "        else:\n",
        "            continue\n",
        "    if k == 0:\n",
        "        current_name = choice(train_data_name_list)\n",
        "    print(current_name)\n",
        "    result_name.append(current_name)\n",
        "\n",
        "\n",
        "print('result_name:',result_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLpvUBM7XmIY"
      },
      "source": [
        "# VGG19+FeatureMatching\n",
        "# The result of the computation\n",
        "#result_names = ['IMG4144_3', 'IMG3250_4', 'IMG3824_2', 'IMG3205_2', 'IMG3699_2', 'IMG3544_5', 'IMG4003_2', 'IMG4178_2', 'IMG3780_5', 'IMG3066_3', 'IMG4212_3', 'IMG4064_2', 'IMG2814_1', 'IMG3949_5', 'IMG2807_4', 'IMG3271_3', 'IMG4228_3', 'IMG3537_4', 'IMG3117_3', 'IMG3817_1', 'IMG4223_5', 'IMG3227_3', 'IMG2819_5', 'IMG4042_1', 'IMG3713_3', 'IMG3799_2', 'IMG2895_1', 'IMG3168_5', 'IMG2922_4', 'IMG4020_5', 'IMG2909_4', 'IMG3018_5', 'IMG3920_5', 'IMG4179_5', 'IMG2839_1', 'IMG3243_1', 'IMG3016_3', 'IMG2781_5', 'IMG2814_1', 'IMG2903_4', 'IMG3012_3', 'IMG2951_5', 'IMG4137_1', 'IMG3323_1', 'IMG3791_4', 'IMG3581_5', 'IMG3333_1', 'IMG3865_3', 'IMG2985_5', 'IMG3008_3', 'IMG3353_2', 'IMG3071_1', 'IMG3823_3', 'IMG4242_1', 'IMG2882_5', 'IMG3330_2', 'IMG2805_2', 'IMG2752_1', 'IMG3070_3', 'IMG3219_4', 'IMG4041_5', 'IMG3219_4', 'IMG4093_3', 'IMG3177_5', 'IMG4157_1', 'IMG3841_2', 'IMG3128_3', 'IMG3599_5', 'IMG2914_1', 'IMG3002_4', 'IMG2966_5', 'IMG3832_5', 'IMG3936_3', 'IMG3756_3', 'IMG3237_5', 'IMG3471_5', 'IMG3932_1', 'IMG4206_3', 'IMG3949_2', 'IMG3632_5', 'IMG3036_3', 'IMG3671_5', 'IMG3782_4', 'IMG2782_3', 'IMG3298_1', 'IMG3719_4', 'IMG2902_1', 'IMG3015_1', 'IMG3083_2', 'IMG3931_3', 'IMG3651_5', 'IMG3243_1', 'IMG3104_1', 'IMG3857_1', 'IMG3188_2', 'IMG3000_4', 'IMG3969_4', 'IMG3707_1', 'IMG3932_2', 'IMG3732_5', 'IMG3154_2', 'IMG3134_5', 'IMG3168_3', 'IMG2757_5', 'IMG3913_5', 'IMG3623_5', 'IMG2832_1', 'IMG3108_1', 'IMG3582_2', 'IMG2940_4', 'IMG3515_2', 'IMG3172_4', 'IMG2943_5', 'IMG3961_1', 'IMG4143_2', 'IMG3219_4', 'IMG4211_2', 'IMG4135_1', 'IMG3053_4', 'IMG3250_4', 'IMG3217_1', 'IMG3108_2', 'IMG3759_5', 'IMG3873_3', 'IMG2889_5', 'IMG3184_5', 'IMG3969_2', 'IMG4151_1', 'IMG4178_2', 'IMG4159_2', 'IMG3732_5', 'IMG3237_1', 'IMG3143_1', 'IMG3729_5', 'IMG3433_3', 'IMG2992_2', 'IMG2752_3', 'IMG3237_1', 'IMG4108_5', 'IMG3786_1', 'IMG3525_4', 'IMG2953_5', 'IMG2873_4', 'IMG3374_3', 'IMG3893_2', 'IMG4032_4', 'IMG3002_3', 'IMG3887_1', 'IMG3079_3', 'IMG4041_5', 'IMG4155_3', 'IMG2861_1', 'IMG3373_4', 'IMG3099_3', 'IMG2948_4', 'IMG2760_2', 'IMG2792_3', 'IMG4028_3', 'IMG4185_4', 'IMG3307_2', 'IMG3706_2', 'IMG2762_3', 'IMG3131_1', 'IMG3889_3', 'IMG2745_4', 'IMG3818_1', 'IMG2819_4', 'IMG2932_5', 'IMG3612_4', 'IMG4185_4', 'IMG3468_2', 'IMG3292_1', 'IMG3108_1', 'IMG3711_3', 'IMG3431_1', 'IMG4151_2', 'IMG3860_3', 'IMG2878_3', 'IMG4156_2', 'IMG2974_1', 'IMG3754_5', 'IMG2941_2', 'IMG3190_3', 'IMG3031_3', 'IMG3713_3', 'IMG3201_2', 'IMG3866_1', 'IMG3166_3', 'IMG4116_1', 'IMG4125_4', 'IMG4074_4', 'IMG3248_1', 'IMG2940_3', 'IMG4083_4', 'IMG2941_2', 'IMG3663_2', 'IMG2987_3', 'IMG4242_2', 'IMG3777_4', 'IMG3865_3', 'IMG3333_1', 'IMG4155_3', 'IMG2932_4', 'IMG2820_2', 'IMG4178_2', 'IMG4017_2', 'IMG2851_5', 'IMG2842_2', 'IMG4116_1', 'IMG2814_1', 'IMG4001_2', 'IMG3257_3', 'IMG3869_4', 'IMG3004_1', 'IMG4011_4', 'IMG2878_2', 'IMG3651_5', 'IMG3674_3', 'IMG3867_2', 'IMG3580_3', 'IMG3411_2', 'IMG3816_5', 'IMG2989_4', 'IMG3230_1', 'IMG3051_1', 'IMG2863_3', 'IMG4147_3', 'IMG2774_1', 'IMG3903_3', 'IMG3047_1', 'IMG3207_3', 'IMG4099_4', 'IMG3172_2', 'IMG4234_1', 'IMG2925_2', 'IMG3065_2', 'IMG2889_5', 'IMG2970_1', 'IMG2857_1', 'IMG3545_3', 'IMG4104_5', 'IMG3861_3', 'IMG2985_5', 'IMG4101_2', 'IMG3572_1', 'IMG3999_5', 'IMG4042_5', 'IMG3034_1', 'IMG4159_3', 'IMG3401_4', 'IMG3291_4', 'IMG3796_3', 'IMG4074_5', 'IMG4215_4', 'IMG2816_1', 'IMG3493_4', 'IMG3165_4', 'IMG3195_2', 'IMG4162_4', 'IMG3049_2', 'IMG3162_5', 'IMG4212_3', 'IMG2746_4', 'IMG3808_2', 'IMG3666_5', 'IMG4242_2', 'IMG3771_1', 'IMG2883_4', 'IMG4061_4', 'IMG2941_5', 'IMG4178_3', 'IMG2851_2', 'IMG2895_4', 'IMG4116_1', 'IMG2944_3', 'IMG3355_2', 'IMG3184_3', 'IMG3882_2', 'IMG3798_2', 'IMG4239_1', 'IMG2805_3', 'IMG3620_4', 'IMG4123_4', 'IMG4006_2', 'IMG2786_4', 'IMG3664_4', 'IMG3190_3', 'IMG3561_2', 'IMG3112_2', 'IMG3723_2', 'IMG3184_2', 'IMG2827_4', 'IMG3318_1', 'IMG3865_3', 'IMG3676_2', 'IMG3409_1', 'IMG3071_2', 'IMG2993_2', 'IMG3241_4', 'IMG3782_4', 'IMG2769_5', 'IMG3839_3', 'IMG3910_3', 'IMG2991_4', 'IMG4024_5', 'IMG4062_4', 'IMG2869_1', 'IMG4172_1', 'IMG3969_2', 'IMG2812_1', 'IMG4026_2', 'IMG3681_1', 'IMG2920_3', 'IMG2921_4', 'IMG3478_2', 'IMG2905_2', 'IMG3237_5', 'IMG3085_4', 'IMG2812_1', 'IMG2966_4', 'IMG4157_1', 'IMG4212_2', 'IMG3960_3', 'IMG2894_3', 'IMG3799_3', 'IMG2795_5', 'IMG3059_3', 'IMG3084_3', 'IMG3727_3', 'IMG4200_2', 'IMG3231_5', 'IMG3193_4', 'IMG3837_5', 'IMG4074_5', 'IMG2807_5', 'IMG3696_5', 'IMG3367_4', 'IMG3024_1', 'IMG3969_2', 'IMG4225_2', 'IMG3071_3', 'IMG3271_1', 'IMG3037_1', 'IMG3544_4', 'IMG4035_2', 'IMG2989_4', 'IMG2832_5', 'IMG4181_2', 'IMG3620_4', 'IMG2897_5', 'IMG3226_2', 'IMG3469_5', 'IMG3342_3', 'IMG3347_2', 'IMG3231_3', 'IMG3936_4', 'IMG3169_3', 'IMG3568_5', 'IMG3229_2', 'IMG2782_3', 'IMG3809_1', 'IMG4154_1', 'IMG3776_2', 'IMG3102_1', 'IMG3868_4', 'IMG3879_3', 'IMG2874_2', 'IMG3191_2', 'IMG3261_4', 'IMG4067_5', 'IMG3242_1', 'IMG4196_5', 'IMG4174_5', 'IMG3936_1', 'IMG3026_3', 'IMG2931_4', 'IMG3096_5', 'IMG3912_5', 'IMG3772_5', 'IMG3668_1', 'IMG3088_5', 'IMG3241_4', 'IMG3323_1', 'IMG3561_2', 'IMG4162_4', 'IMG4242_2', 'IMG3782_4', 'IMG3489_5', 'IMG3691_5', 'IMG3202_2', 'IMG3620_4', 'IMG3666_2', 'IMG3197_2', 'IMG3839_4', 'IMG3971_1', 'IMG2991_4', 'IMG4070_2', 'IMG3049_2', 'IMG4038_5', 'IMG3544_4', 'IMG3975_3', 'IMG3190_2', 'IMG2832_4', 'IMG2840_1', 'IMG4066_4', 'IMG4028_3', 'IMG3984_4', 'IMG3096_1', 'IMG2940_4', 'IMG3346_4', 'IMG3023_5', 'IMG3744_4', 'IMG2943_1', 'IMG3089_5', 'IMG3818_2', 'IMG3052_5', 'IMG3292_5', 'IMG4062_5', 'IMG3894_1', 'IMG3122_1', 'IMG4185_4', 'IMG3651_5', 'IMG3242_5', 'IMG2753_4', 'IMG3929_2', 'IMG4207_1', 'IMG4071_4', 'IMG4094_3', 'IMG3984_5', 'IMG3054_2', 'IMG3210_4', 'IMG2940_3', 'IMG4204_1', 'IMG2880_1', 'IMG3897_2', 'IMG3345_4', 'IMG2802_1', 'IMG2786_2', 'IMG3197_2', 'IMG2932_4', 'IMG3691_5', 'IMG3611_1', 'IMG4054_2', 'IMG3868_1', 'IMG2860_4', 'IMG3346_4', 'IMG3284_2', 'IMG3861_3', 'IMG3427_5', 'IMG2940_3', 'IMG2882_3', 'IMG3280_4', 'IMG3083_1', 'IMG3805_2', 'IMG3820_3', 'IMG4238_5', 'IMG3881_1', 'IMG3165_3', 'IMG3713_3', 'IMG4187_1', 'IMG3286_1', 'IMG3291_5', 'IMG2855_1', 'IMG3763_2', 'IMG3707_1', 'IMG3908_5', 'IMG3580_3', 'IMG4242_1', 'IMG3155_2', 'IMG3693_3', 'IMG3257_3', 'IMG3369_4', 'IMG4208_1', 'IMG3955_2', 'IMG3790_5', 'IMG3505_1', 'IMG4089_1', 'IMG3759_5', 'IMG3622_3', 'IMG3955_2', 'IMG3318_1', 'IMG2940_3', 'IMG3067_1', 'IMG3722_2', 'IMG3130_1', 'IMG3476_2', 'IMG3242_1', 'IMG4150_3', 'IMG3987_2', 'IMG2834_4', 'IMG4144_3', 'IMG2911_2', 'IMG3713_3', 'IMG3148_5', 'IMG3734_2', 'IMG3123_4', 'IMG3854_3', 'IMG4188_1', 'IMG4188_1', 'IMG4020_5', 'IMG3006_2', 'IMG2887_1', 'IMG3270_3', 'IMG3499_3', 'IMG2987_3', 'IMG3193_4', 'IMG3520_4', 'IMG3160_4', 'IMG2995_1', 'IMG2974_1', 'IMG4202_3', 'IMG3088_1', 'IMG3037_5', 'IMG4162_1', 'IMG3083_2', 'IMG2769_5', 'IMG3154_2', 'IMG2854_4', 'IMG3108_2', 'IMG2832_4', 'IMG2940_4', 'IMG3805_5', 'IMG3200_5', 'IMG3389_4', 'IMG4027_4', 'IMG3732_5', 'IMG4004_2', 'IMG2865_3', 'IMG2979_5', 'IMG3133_1', 'IMG3432_3', 'IMG2940_4', 'IMG3117_1', 'IMG3984_5', 'IMG3054_5', 'IMG3496_4', 'IMG4053_3', 'IMG3106_2', 'IMG3134_4', 'IMG3250_4', 'IMG3694_1', 'IMG3274_3', 'IMG3883_1', 'IMG3699_4', 'IMG3093_2', 'IMG3789_4', 'IMG3114_5', 'IMG2845_4', 'IMG3669_5', 'IMG4157_1', 'IMG3946_4', 'IMG3020_4', 'IMG4060_1', 'IMG2940_4', 'IMG3490_4', 'IMG3495_4', 'IMG3347_2', 'IMG3361_2', 'IMG3624_1', 'IMG4099_5', 'IMG4122_3', 'IMG3347_2', 'IMG2787_2', 'IMG2761_2', 'IMG4117_1', 'IMG3508_5', 'IMG3763_2', 'IMG2940_4', 'IMG3946_4', 'IMG3693_3', 'IMG3127_2', 'IMG3026_3', 'IMG3583_5', 'IMG4174_1', 'IMG4242_1', 'IMG3129_2', 'IMG3237_5', 'IMG3379_5', 'IMG3920_3', 'IMG3987_3', 'IMG2974_1', 'IMG3254_4', 'IMG3612_4', 'IMG3956_3', 'IMG3840_1', 'IMG4239_3', 'IMG3580_3', 'IMG2845_4', 'IMG2943_4', 'IMG2800_2', 'IMG3839_3', 'IMG3117_5', 'IMG4088_3', 'IMG3839_3', 'IMG4178_2', 'IMG2841_4', 'IMG3651_4', 'IMG3000_4', 'IMG4117_3', 'IMG3049_3', 'IMG3879_3', 'IMG3916_2', 'IMG3174_3', 'IMG2845_5', 'IMG3640_3', 'IMG3225_5', 'IMG3154_2', 'IMG2749_4', 'IMG3948_2', 'IMG4130_4', 'IMG4180_4', 'IMG2844_3', 'IMG4164_1', 'IMG4131_4', 'IMG3839_5', 'IMG2955_1', 'IMG4178_2', 'IMG2771_1', 'IMG3902_5', 'IMG2940_4', 'IMG3824_3', 'IMG3930_5', 'IMG4206_5', 'IMG3691_3', 'IMG3886_5', 'IMG4157_1', 'IMG2832_4', 'IMG3622_3', 'IMG4242_2', 'IMG3919_2', 'IMG3799_4', 'IMG4229_5', 'IMG3432_5', 'IMG2986_1', 'IMG3537_5', 'IMG4116_1', 'IMG3860_3', 'IMG3868_3', 'IMG2786_2', 'IMG4017_5', 'IMG2816_3', 'IMG4062_4', 'IMG3782_4', 'IMG2829_3', 'IMG3868_1', 'IMG4116_1', 'IMG3235_3', 'IMG3499_4', 'IMG2788_5', 'IMG3749_2', 'IMG3433_1', 'IMG3763_1', 'IMG3857_1', 'IMG3884_1', 'IMG4100_3', 'IMG4183_2', 'IMG2894_5', 'IMG3685_1', 'IMG3035_2', 'IMG4078_2', 'IMG4002_2', 'IMG3911_4', 'IMG3939_5', 'IMG3713_3', 'IMG4105_5', 'IMG2932_5', 'IMG2940_3', 'IMG3224_2', 'IMG3612_4', 'IMG3840_2', 'IMG3012_5', 'IMG3865_3', 'IMG2757_3', 'IMG3931_1', 'IMG3333_5', 'IMG4120_2', 'IMG4156_2', 'IMG4242_1', 'IMG3911_2', 'IMG2786_5', 'IMG3941_3', 'IMG3761_4', 'IMG3219_4', 'IMG3897_2', 'IMG3913_5', 'IMG3890_3', 'IMG2941_1', 'IMG2940_3', 'IMG3535_1', 'IMG3242_5', 'IMG3713_3', 'IMG2956_4', 'IMG2982_4', 'IMG3081_4', 'IMG3517_2', 'IMG3696_5', 'IMG2953_2', 'IMG4117_4', 'IMG3812_2', 'IMG4221_2', 'IMG3229_2', 'IMG2989_3', 'IMG3237_5', 'IMG2840_5', 'IMG4239_3', 'IMG4184_5', 'IMG3237_5', 'IMG4070_5', 'IMG2962_3', 'IMG3076_5', 'IMG3389_4', 'IMG4238_2', 'IMG2974_1', 'IMG2950_4', 'IMG4055_4', 'IMG3748_1', 'IMG3155_2', 'IMG3751_1', 'IMG3085_4', 'IMG4089_3', 'IMG2832_4', 'IMG4122_3', 'IMG2877_1', 'IMG2842_1', 'IMG3291_5', 'IMG3486_4', 'IMG3237_5', 'IMG4113_4', 'IMG4090_2', 'IMG3882_5', 'IMG3210_1', 'IMG4148_5', 'IMG4187_5', 'IMG3347_2', 'IMG3174_3', 'IMG4056_3', 'IMG3393_1', 'IMG2895_4', 'IMG3868_1', 'IMG3181_3', 'IMG4185_5', 'IMG3905_3', 'IMG4122_3', 'IMG3371_5', 'IMG3219_4', 'IMG4206_5', 'IMG3038_4', 'IMG3648_1', 'IMG3702_2', 'IMG3172_2', 'IMG3042_5', 'IMG4242_1', 'IMG3951_1', 'IMG4026_2', 'IMG3545_3', 'IMG4197_5', 'IMG4155_3', 'IMG2815_4', 'IMG3250_4', 'IMG3012_2', 'IMG2759_3', 'IMG3177_2', 'IMG3997_1', 'IMG3241_4', 'IMG3687_1', 'IMG4069_4', 'IMG2925_2', 'IMG3333_1', 'IMG3979_2', 'IMG3219_4', 'IMG4062_4', 'IMG3732_5', 'IMG2769_2', 'IMG3612_4', 'IMG3342_3', 'IMG3051_1', 'IMG3125_4', 'IMG3948_2', 'IMG2833_3', 'IMG3241_2', 'IMG3205_5', 'IMG3478_2', 'IMG4089_5', 'IMG2810_5', 'IMG3101_5', 'IMG3499_1', 'IMG2755_4', 'IMG3362_2', 'IMG2869_3', 'IMG3205_2', 'IMG3190_3', 'IMG3747_4', 'IMG3069_5', 'IMG3133_3', 'IMG4052_5', 'IMG4230_5', 'IMG2912_3', 'IMG3355_1', 'IMG3188_5', 'IMG3327_1', 'IMG2922_4', 'IMG3791_4', 'IMG3229_2', 'IMG3561_2', 'IMG3451_3', 'IMG4038_2', 'IMG3219_3', 'IMG3697_2', 'IMG3389_5', 'IMG4056_3', 'IMG3739_2', 'IMG3795_1', 'IMG4239_4', 'IMG3071_2', 'IMG4168_5', 'IMG3887_1', 'IMG3879_4', 'IMG4100_1', 'IMG2965_3', 'IMG3436_5', 'IMG3055_1', 'IMG4122_3', 'IMG2974_1', 'IMG4163_4', 'IMG3396_5', 'IMG3460_2', 'IMG2960_2', 'IMG2837_5', 'IMG3031_2', 'IMG3860_3', 'IMG4168_4', 'IMG4039_4', 'IMG2810_1', 'IMG3753_5', 'IMG4042_5', 'IMG3675_5', 'IMG2929_5', 'IMG2748_5', 'IMG4185_4', 'IMG2914_2', 'IMG3744_5', 'IMG2790_5', 'IMG3213_1', 'IMG3605_1', 'IMG2845_5', 'IMG3199_2', 'IMG3605_1', 'IMG2825_1', 'IMG3508_5', 'IMG3201_3', 'IMG3723_3', 'IMG4123_2', 'IMG3882_5', 'IMG3620_4', 'IMG3707_1', 'IMG2816_4', 'IMG2976_2', 'IMG3687_5', 'IMG2814_1', 'IMG3865_3', 'IMG3742_4', 'IMG4187_5', 'IMG3713_3', 'IMG3143_1', 'IMG3741_3', 'IMG3902_1', 'IMG3167_3', 'IMG3544_4', 'IMG3056_2', 'IMG2987_1', 'IMG2940_3', 'IMG3217_1', 'IMG2971_3', 'IMG2893_4', 'IMG4123_5', 'IMG3936_1', 'IMG3743_5', 'IMG3713_3', 'IMG2954_4', 'IMG4112_4', 'IMG3508_1', 'IMG3936_2', 'IMG3802_4', 'IMG4157_1', 'IMG4078_5', 'IMG3120_2', 'IMG4206_1', 'IMG4123_5', 'IMG3138_4', 'IMG3816_1', 'IMG3341_3', 'IMG2759_3', 'IMG3114_4', 'IMG3274_5', 'IMG2768_1', 'IMG3768_2', 'IMG4188_1', 'IMG3040_1', 'IMG2837_2', 'IMG3432_3', 'IMG3798_2', 'IMG2786_4', 'IMG3493_3', 'IMG3165_3', 'IMG4177_3', 'IMG3079_1', 'IMG3795_1', 'IMG3791_1', 'IMG4242_1', 'IMG4044_1', 'IMG3396_5', 'IMG3065_3', 'IMG4138_5', 'IMG3311_3', 'IMG4062_4', 'IMG4173_1', 'IMG3505_1', 'IMG2882_2', 'IMG4180_4', 'IMG4226_3', 'IMG3760_1', 'IMG2988_5', 'IMG4112_4', 'IMG2927_4', 'IMG3333_1', 'IMG3949_3', 'IMG4234_5', 'IMG4182_4', 'IMG2848_4', 'IMG2805_1', 'IMG3821_2', 'IMG3568_4', 'IMG3710_4', 'IMG3153_1', 'IMG3656_4', 'IMG3348_2', 'IMG2778_2', 'IMG2971_3', 'IMG3043_5', 'IMG3804_3', 'IMG3776_3', 'IMG3325_4', 'IMG3169_3', 'IMG3672_5', 'IMG3173_4', 'IMG3186_2', 'IMG2970_2', 'IMG2959_4', 'IMG3237_5', 'IMG2755_4', 'IMG3703_1', 'IMG3861_3', 'IMG4185_4', 'IMG3257_2', 'IMG3517_3', 'IMG2974_5', 'IMG2889_1', 'IMG3342_3', 'IMG4055_2', 'IMG4061_3', 'IMG3186_2', 'IMG3975_1', 'IMG3663_1', 'IMG3469_2', 'IMG3220_4', 'IMG3073_4', 'IMG3792_4', 'IMG2985_3', 'IMG4011_4', 'IMG2779_1', 'IMG3651_4', 'IMG2986_1', 'IMG3882_2', 'IMG3213_5', 'IMG3260_2', 'IMG3162_4', 'IMG3222_3', 'IMG3065_3', 'IMG3966_2', 'IMG2874_3', 'IMG3060_5', 'IMG3207_4', 'IMG4175_2', 'IMG3742_4', 'IMG3984_3', 'IMG2974_1', 'IMG3245_1', 'IMG3100_4', 'IMG3006_5', 'IMG3627_1', 'IMG2884_3', 'IMG4112_4', 'IMG3612_4', 'IMG3140_1', 'IMG3882_4', 'IMG3043_4', 'IMG2995_5', 'IMG3860_3', 'IMG2831_4', 'IMG3763_1', 'IMG3861_4', 'IMG3865_3', 'IMG3025_3', 'IMG3932_5', 'IMG3237_5', 'IMG3868_3', 'IMG3916_1', 'IMG3527_5', 'IMG2940_2', 'IMG4062_4', 'IMG3237_5', 'IMG3432_2', 'IMG3239_1', 'IMG2869_2', 'IMG3079_3', 'IMG3204_4', 'IMG3839_3', 'IMG3411_2', 'IMG2971_3', 'IMG3371_5', 'IMG2922_3', 'IMG3713_3', 'IMG4133_5', 'IMG2845_5', 'IMG3699_2', 'IMG3292_1', 'IMG3318_1', 'IMG4035_1', 'IMG2940_3', 'IMG3727_3', 'IMG2895_1', 'IMG2940_4', 'IMG2971_3', 'IMG2812_1', 'IMG3298_2', 'IMG4137_1', 'IMG4169_5', 'IMG3197_3', 'IMG3651_5', 'IMG4196_1', 'IMG2988_5', 'IMG3255_5', 'IMG3975_1', 'IMG4041_5', 'IMG3237_5', 'IMG2998_1', 'IMG2814_1', 'IMG2851_1', 'IMG3757_1', 'IMG2988_3', 'IMG3620_4', 'IMG3145_5', 'IMG3375_3', 'IMG3495_4', 'IMG3006_5', 'IMG3641_3', 'IMG3795_1', 'IMG3826_5', 'IMG2911_2', 'IMG3798_2', 'IMG4050_3', 'IMG4157_1', 'IMG4116_1', 'IMG3243_3', 'IMG2770_1', 'IMG3197_5', 'IMG3912_1', 'IMG3970_5', 'IMG3953_1', 'IMG4132_3', 'IMG3038_4', 'IMG3936_3', 'IMG3170_4', 'IMG4037_3', 'IMG2838_1', 'IMG2946_3', 'IMG3755_1', 'IMG3828_1', 'IMG3877_5', 'IMG3525_4', 'IMG3232_1', 'IMG4112_3', 'IMG2954_4', 'IMG4157_1', 'IMG3994_5', 'IMG3680_3', 'IMG3752_4', 'IMG3719_3', 'IMG3115_5', 'IMG3945_2', 'IMG3700_5', 'IMG3325_5', 'IMG4090_2', 'IMG4112_4', 'IMG4099_1', 'IMG2820_1', 'IMG3836_2', 'IMG3516_5', 'IMG2833_4', 'IMG4229_2', 'IMG3930_5', 'IMG3812_1', 'IMG3499_5', 'IMG4196_1', 'IMG4039_4', 'IMG3478_2', 'IMG3976_5', 'IMG4206_2', 'IMG3796_3', 'IMG3839_3', 'IMG2956_3', 'IMG4152_3', 'IMG4146_4', 'IMG3796_1', 'IMG4242_1', 'IMG4175_5', 'IMG3181_3', 'IMG3997_1', 'IMG3932_4', 'IMG4083_1', 'IMG3984_4', 'IMG4193_3', 'IMG3925_4', 'IMG4181_2', 'IMG3743_5', 'IMG2892_3', 'IMG2882_3', 'IMG2892_2', 'IMG3946_5', 'IMG3712_5', 'IMG3061_5', 'IMG3962_2', 'IMG4117_4', 'IMG3777_4', 'IMG2967_5', 'IMG2771_5', 'IMG3920_3', 'IMG3084_1', 'IMG2825_1', 'IMG3691_4', 'IMG3190_3', 'IMG2974_1', 'IMG3456_3', 'IMG2997_5', 'IMG2815_5', 'IMG3023_2', 'IMG2803_1', 'IMG3205_3', 'IMG3656_4', 'IMG3826_4', 'IMG3071_2', 'IMG4093_2', 'IMG2991_5', 'IMG3201_1', 'IMG4185_1', 'IMG3537_5', 'IMG3025_2', 'IMG3913_5', 'IMG3752_1', 'IMG3229_2', 'IMG3025_1', 'IMG2921_4', 'IMG3027_1', 'IMG3167_5', 'IMG3241_2', 'IMG4017_5', 'IMG2954_4', 'IMG3251_4', 'IMG3271_3', 'IMG2997_5', 'IMG4185_4', 'IMG3182_2', 'IMG3009_1', 'IMG3024_5', 'IMG2777_3', 'IMG3941_3', 'IMG2932_5', 'IMG4219_3', 'IMG3665_5', 'IMG4041_1', 'IMG4093_4', 'IMG3675_5', 'IMG4056_3', 'IMG3089_5', 'IMG2796_4', 'IMG4174_2', 'IMG3237_5', 'IMG4155_3', 'IMG2786_2', 'IMG4199_2', 'IMG3190_3', 'IMG3347_1', 'IMG3962_4', 'IMG4105_3', 'IMG3122_5', 'IMG3271_3', 'IMG3312_5', 'IMG3937_1', 'IMG2813_1', 'IMG4152_2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5zWBwZDXxPs"
      },
      "source": [
        "import pandas as pd\n",
        "# import pandas.dataframe as df\n",
        "\n",
        "# This is use to read the result file from VGG19\n",
        "output_csv = pd.read_csv('./output.csv')\n",
        "\n",
        "# This is the output file of feature match which only contains the names\n",
        "test_file_path = './imagenames-CGG19+FeatureMatching.csv'\n",
        "\n",
        "# This is the train data name and coordinate csv file\n",
        "train_csv = pd.read_csv('./train.csv')\n",
        "\n",
        "# This is the original imagenames(Test names) CSV file\n",
        "test_csv = pd.read_csv('./imagenames.csv')\n",
        "\n",
        "# This function is to make the test name as a list\n",
        "test_name_list = output_csv['pred_img_name'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kxa1Vd3Xx-m"
      },
      "source": [
        "with open(test_file_path, 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id','x','y'])\n",
        "    for test_name, result_name in zip(test_name_list, result_names):\n",
        "      a = train_csv.loc[train_csv['id'] == result_name]\n",
        "      writer.writerow([test_name,a['x'].values[0],a['y'].values[0]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}